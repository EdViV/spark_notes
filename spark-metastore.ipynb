{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bc23b56-3927-4e5e-ae2f-517c2ec779d6",
   "metadata": {},
   "source": [
    "# Spark Catalog\n",
    "\n",
    "Let us say **spark** is an object of type **SparkSession**. there is an attribute of **spark** called **catalog**.\n",
    "\n",
    "We can access *catalog* using **spark.catalog** and permanently or temporarily create tables or views on top of dat in a DataFrame.\n",
    "\n",
    "Metadata such as table names, column names, data types, etc. For the permanent tables or views will be stored in Metastore. We can acces that metadata using **spark.catalog** whichs is exposed as part of the SparkSession object. **spark.catalog** also provides us the details related to temporary views athat are being created. The metadata of these temporary views will not be stores in Spark Metastore.\n",
    "\n",
    "Permanent tables are created using databases in saprk metastore. If not specified, the tables will be created in **default** database.\n",
    "\n",
    "Here are some of the tasks that can be performed using spark.catalog object: \n",
    "1. Check current database and seitch to different databases.\n",
    "2. Create permanent table in metastore.\n",
    "3. Create or drop temporary views.\n",
    "4. Regsiter functions.\n",
    "\n",
    "All of the above commands can be passed using SQL style commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070eef79-7a83-48ee-b39c-b1b9296c5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Spark Metastore'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "712524a9-fab7-486e-98b6-2a11fd7dc894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.catalog.Catalog at 0x7ff9d90a9b70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cfefa6-302a-476a-a466-b2af586728d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN CELL IF YOU WANT TO SEE ALL OF AVAILABLE COMMANDS\n",
    "\n",
    "help(spark.catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57568a57-fab6-4cf9-969e-9ead23528ec6",
   "metadata": {},
   "source": [
    "# Creating Metastore Tables using **catalog**\n",
    "\n",
    "DataFrames can be written into Metastore Tables using API's such as **saveAsTable** and **insertInto** available as part of **write** on top of dataframe type objects.\n",
    "\n",
    "Databases can be created using **spark.sql (\"CREATE DATABASE *database_name*\")**. We can list databases using **spark.sql** or **spark.catalog.listDatabases()**\n",
    "\n",
    "A new table can be created from a DataFrame using **saveAsTable**. An empty table can be created by using **spark.catalog.createTable** or **spark.catalog.createExternalTable**.\n",
    "\n",
    "We can prefix the database name to write data into tables belonging to a particular database. if the database is not specified then the session will be default. Also the current session can be attached or connected to a specific database using **spark.catalog.setCurrentDatabase**.\n",
    "\n",
    "The **saveAsTable** method allows for modes: append, overwrite and error. The default mode is error. The **insertInto** method allows for modes: append and overwrite, default mode is append."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fead113d-6e92-4283-abc8-93fb418173a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Sets the given Spark runtime configuration property.\n",
       "\n",
       ".. versionadded:: 2.0\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/spark3/python/pyspark/sql/conf.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.conf.set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8150fe3c-4d34-4c1a-b425-1fa5407afe08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE DATABASE demo_db\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3755ef9-235c-48d7-8faf-6af48cffb798",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(\"demo_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad171ac5-9909-40cd-8272-aed1f9c6353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Database(name='default', description='Default Hive database', locationUri='hdfs://localhost:9000/user/hive/warehouse'),\n",
       " Database(name='demo_db', description='', locationUri='file:/home/evivancovid/pyspark-exercises/spark-warehouse/demo_db.db'),\n",
       " Database(name='nyse_db', description='', locationUri='hdfs://localhost:9000/user/hive/warehouse/nyse_db.db')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0911d4ac-0a0a-41f0-aedb-c28bdf102989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>namespace</th></tr>\n",
       "<tr><td>default</td></tr>\n",
       "<tr><td>demo_db</td></tr>\n",
       "<tr><td>nyse_db</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+\n",
       "|namespace|\n",
       "+---------+\n",
       "|  default|\n",
       "|  demo_db|\n",
       "|  nyse_db|\n",
       "+---------+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"SHOW DATABASES\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54cb12ca-9ab3-468a-adea-020329cce673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data Frame which contain one column by name dummy and one row with value X.\n",
    "\n",
    "l = [(\"X\", )]\n",
    "df = spark.createDataFrame(l, schema = \"dummy STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c330968-9646-422e-a31b-729a36b86e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='dual', database='demo_db', description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24db3668-2f09-433b-b88d-1e6465ba7657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|dummy|\n",
      "+-----+\n",
      "|    X|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2531576b-34ca-472e-81b0-622be7f484fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table by name dual for the above Data Frame in the database created.\n",
    "\n",
    "df.write.saveAsTable(\"dual\", mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec629065-9740-47a6-90b0-2b005ec346ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='dual', database='demo_db', description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b1d6302-346e-49ac-b030-b9b4cc1c6263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|dummy|\n",
      "+-----+\n",
      "|    X|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"dual\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9c2436c-9ae3-4ce3-897b-c61232604455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE dual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8f43cf-89d2-4237-8b92-7e53f5f7023b",
   "metadata": {},
   "source": [
    "### Create empty table and insert data into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce395117-5585-40e5-9e05-3cf815b346e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|dummy|\n",
      "+-----+\n",
      "|    X|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f8fbd1b-9313-4ee8-a6c7-0552d2d25f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "396d6b84-7cd5-4ade-bd80-b5027fedf2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>dummy</th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+\n",
       "|dummy|\n",
       "+-----+\n",
       "+-----+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.createTable(\"dual\", schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e66985a4-e9ec-488e-a7fb-4aab3657d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.insertInto(\"dual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d364e466-f4d2-44c4-9dfd-8e4e13376369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|dummy|\n",
      "+-----+\n",
      "|    X|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"dual\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b8d4c-0c29-4af4-bcef-1d39c7debc2e",
   "metadata": {},
   "source": [
    "# Inferring Schema for Tables\n",
    "\n",
    "When we want to create a table using **spark.catalog.createTable** or using **spark.catalog.createExternalTable**, the schema need to be specified.\n",
    "Spark can infer the schema from a DataFrame and can then be passed using a **StructType** object while creating the table. A StructType object takes a list of objects of type **StructField**. A **StructField** object is built using column name and data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d240c44-00db-4ef0-a496-2b5d2716ebe6",
   "metadata": {},
   "source": [
    "# Define Schema for Tables using StructType\n",
    "\n",
    "Spark can infer the schema from a DataFrame or can be passed using a **StructType** object while creating the table. A StructType object takes a list of objects of type **StructField**. A **StructField** object is built using column name and data type. All data types are available under **pyspark.sql.types**. We need to pass table name and schema when using **spark.catalog.createTable** and we have to pass path along with name and schema when using **spark.catalog.createExternalTable**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c15ca167-4fb4-43c8-86f0-783f0979163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = [(1, \"Scott\", \"Tiger\", 1000.0,\"united states\"),\n",
    "                     (2, \"Henry\", \"Ford\", 1250.0,\"India\"),\n",
    "                     (3, \"Nick\", \"Junior\", 750.0,\"united KINGDOM\"),\n",
    "                     (4, \"Bill\", \"Gomes\", 1500.0,\"AUSTRALIA\")\n",
    "                ]\n",
    "\n",
    "employeesDF = spark. \\\n",
    "    createDataFrame(employees,\n",
    "                    schema=\"\"\"employee_id INT, first_name STRING, \n",
    "                    last_name STRING, salary FLOAT, nationality STRING\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02628355-6ea0-4d25-9d4b-a54ef1cde8b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table employees already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0ef6e57178fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#Create table by passing StructType object as Schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"employees\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memployeesSchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark3/python/pyspark/sql/catalog.py\u001b[0m in \u001b[0;36mcreateTable\u001b[0;34m(self, tableName, path, source, schema, description, **options)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mscala_datatype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseDataType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             df = self._jcatalog.createTable(\n\u001b[0;32m--> 195\u001b[0;31m                 tableName, source, scala_datatype, description, options)\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark3/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table employees already exists."
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType, FloatType\n",
    "\n",
    "#Build StructType object using StructField list.\n",
    "\n",
    "employeesSchema = StructType([\n",
    "    StructField(\"employee_id\", IntegerType()),\n",
    "    StructField(\"first_name\", StringType()),\n",
    "    StructField(\"last_name\", StringType()),\n",
    "    StructField(\"salary\", FloatType()),\n",
    "    StructField(\"nationality\", StringType())\n",
    "])\n",
    "\n",
    "#Create table by passing StructType object as Schema\n",
    "\n",
    "spark.catalog.createTable(\"employees\", schema = employeesSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb4ea77-eaf2-4fe1-b994-62c9325c7887",
   "metadata": {},
   "source": [
    "# Inserting into Existing Tables\n",
    "\n",
    "We can use **insertInto** with modes such as **append** and **overwrite** to insert data into an existing table, if we do not specify a mode, the default mode is **append**.\n",
    "When we use **insertInto** the following happens:\n",
    "1.\tIF the table doesn’t exist, **insertInto** will throw and exception\n",
    "2.\tIf the table exists, by default the data will be appended\n",
    "3.\tWe can alter the above behaviour by using argument **overwrite**, which by default is False, we can pass True to replace existing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35616671-73ff-434a-b57e-1f4ae307f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create employees DataFrame and insert it into already existing employees table (created in above topic)\n",
    "\n",
    "employeesDF.write.insertInto(\"employees\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a643e-1eb4-4160-8ddb-d74b48def251",
   "metadata": {},
   "source": [
    "# Read and Process data from Metastore Tables\n",
    "\n",
    "Using DataFrame API’s we can read tables as follows: \n",
    "We can prefix the database name to read tables belonging to a particular database. \n",
    "When we **read** a table it results in a **DataFrame**. One we have a DataFrame object, we can use functions such as **filter**, **where**, **groupBy**, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a70b58ca-4cad-4a63-8b87-3cc74d69ae74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE DATABASE IF NOT EXISTS evivancovid_nyvenv\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a306ce4e-1916-4be6-80c7-bb8623aba61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>namespace</th></tr>\n",
       "<tr><td>default</td></tr>\n",
       "<tr><td>demo_db</td></tr>\n",
       "<tr><td>evivancovid_nyvenv</td></tr>\n",
       "<tr><td>nyse_db</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------------+\n",
       "|         namespace|\n",
       "+------------------+\n",
       "|           default|\n",
       "|           demo_db|\n",
       "|evivancovid_nyvenv|\n",
       "|           nyse_db|\n",
       "+------------------+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"SHOW DATABASES\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d39247-ae3a-42d0-a942-aa81b8dd7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(\"\"\"evivancovid_nyvenv\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade67f30-1681-464d-8910-10150a4a6ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'evivancovid_nyvenv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58fac2d4-1981-4274-9016-a2eb94b9eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_2000_path = \"/public/data/nyse_years/NYSE_2000.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54eb9106-e006-4e3c-a101-c96ac593cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_2000_df = spark.read.csv(nyse_2000_path, sep = \",\", header = False, schema = \"ticker STRING, trade_date STRING, open_price FLOAT, close_price FLOAT, high FLOAT, low FLOAT, volume INT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1198a8f-3a5b-4b33-9ff2-1f0265b9d20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+------+------+-------+\n",
      "|ticker|trade_date|open_price|close_price|  high|   low| volume|\n",
      "+------+----------+----------+-----------+------+------+-------+\n",
      "|     A|  20000103|     78.75|      78.94| 67.38|  72.0|3343700|\n",
      "|    AA|  20000103|     123.0|     125.34|120.57|121.41|1551600|\n",
      "|   ABB|  20000103|     24.66|      24.66| 24.66| 24.66|      0|\n",
      "|   ABC|  20000103|     3.875|     3.9375|3.8125|  3.89| 696200|\n",
      "|   ABM|  20000103|     10.25|      10.31|  10.0| 10.16| 241600|\n",
      "|   ABT|  20000103|     35.25|       36.0| 34.75|  35.0|4774100|\n",
      "|   ABX|  20000103|     17.56|      18.19| 17.44| 17.69|1509900|\n",
      "|   ACP|  20000103|      7.56|        8.0|  7.56|  7.94|  12600|\n",
      "|   ACV|  20000103|     17.04|      17.13|  16.5| 16.75|  70950|\n",
      "|   ADC|  20000103|     14.37|      14.37| 13.62| 13.94|  24500|\n",
      "|   ADM|  20000103|     10.89|      10.94| 10.77| 10.89| 985413|\n",
      "|   ADX|  20000103|     22.34|       22.5| 22.16| 22.28| 117450|\n",
      "|   AED|  20000103|      18.5|       22.0|  18.5|  22.0|   1675|\n",
      "|   AEE|  20000103|     32.56|      32.62| 31.56| 32.31| 700800|\n",
      "|   AEG|  20000103|     46.55|      47.23| 46.15| 47.23| 368576|\n",
      "|   AEM|  20000103|      7.25|       7.31|  7.19|  7.19|  68400|\n",
      "|   AEP|  20000103|      32.0|       32.0| 31.12| 31.44| 396900|\n",
      "|   AES|  20000103|     37.37|      37.37| 35.62| 36.25|1334400|\n",
      "| AES-C|  20000103|      61.5|       61.5|  59.5|  60.5|  19900|\n",
      "|   AET|  20000103|     6.922|      6.977| 6.883| 6.946| 654700|\n",
      "+------+----------+----------+-----------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyse_2000_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee42996-1f4c-4714-95d0-537b606f291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_2000_df.write.saveAsTable(\"nyse2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4487e706-d7dd-4048-9333-59504ab54d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>database</th><th>tableName</th><th>isTemporary</th></tr>\n",
       "<tr><td>evivancovid_nyvenv</td><td>nyse2000</td><td>false</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------------+---------+-----------+\n",
       "|          database|tableName|isTemporary|\n",
       "+------------------+---------+-----------+\n",
       "|evivancovid_nyvenv| nyse2000|      false|\n",
       "+------------------+---------+-----------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SHOW Tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65deb777-cb70-41c2-b7d4-b00acf49e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_2000 = spark.read.table(\"nyse2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c36176b-d7a1-4688-9f82-0d9b7469a5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|ticker|count|\n",
      "+------+-----+\n",
      "|     K|  260|\n",
      "|   LEN|  260|\n",
      "|   MHF|  260|\n",
      "|   PKE|  260|\n",
      "|   TLI|  260|\n",
      "|   CCK|  260|\n",
      "|   CRS|  260|\n",
      "|   GIS|  260|\n",
      "|   HAE|  260|\n",
      "|   RRD|  260|\n",
      "|   TRK|  260|\n",
      "|   AIV|  260|\n",
      "|   AVX|  260|\n",
      "|   AVY|  260|\n",
      "|   FDC|  260|\n",
      "|  BF.B|  260|\n",
      "|   DTF|  260|\n",
      "|   MGF|  260|\n",
      "|   MMM|  260|\n",
      "|   PKI|  260|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyse_2000.groupBy(\"ticker\"). \\\n",
    "    count(). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3a9c2-cbb2-4c1e-8678-4c93acdaba87",
   "metadata": {},
   "source": [
    "# Creating Partitioned Tables\n",
    "\n",
    "We can create partitioned tables as part of Spark Metastore Tables. There are some challenges when creating partitioned tables directly using **spark.catalog.createTable**, however, if the directories are similar to partitioned tables with data, we should be able to create partitiones tables with no issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec8eecd7-f923-4f09-87be-500c1bec88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format, col, substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "118f9576-a859-46c3-ac3a-6f137272fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.csv(nyse_2000_path, \n",
    "               header = False, \n",
    "               schema = \"ticker STRING, trade_date STRING, open_price FLOAT, close_price FLOAT, high FLOAT, low FLOAT, volume INT\"). \\\n",
    "    withColumn(\"trade_month\", substring(col(\"trade_date\"),1,6)). \\\n",
    "    write. \\\n",
    "    partitionBy(\"trade_month\"). \\\n",
    "    parquet(\"/public/data/nyse_parts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "903f7573-ff48-48f1-be8b-6a9465eb478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   1 evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/_SUCCESS\n",
      "drwxr-xr-x   - evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200001\n",
      "-rw-r--r--   1 evivancovid supergroup     376816 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200001/part-00000-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n",
      "drwxr-xr-x   - evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200002\n",
      "-rw-r--r--   1 evivancovid supergroup     358443 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200002/part-00000-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n",
      "drwxr-xr-x   - evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200003\n",
      "-rw-r--r--   1 evivancovid supergroup     421018 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200003/part-00000-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n",
      "drwxr-xr-x   - evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200004\n",
      "-rw-r--r--   1 evivancovid supergroup     372077 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200004/part-00000-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n",
      "drwxr-xr-x   - evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200005\n",
      "-rw-r--r--   1 evivancovid supergroup     399823 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200005/part-00000-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n",
      "drwxr-xr-x   - evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200006\n",
      "-rw-r--r--   1 evivancovid supergroup     385689 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200006/part-00000-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n",
      "drwxr-xr-x   - evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200007\n",
      "-rw-r--r--   1 evivancovid supergroup     385875 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200007/part-00000-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n",
      "drwxr-xr-x   - evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200008\n",
      "-rw-r--r--   1 evivancovid supergroup     373626 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200008/part-00000-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n",
      "-rw-r--r--   1 evivancovid supergroup      67853 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200008/part-00001-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n",
      "drwxr-xr-x   - evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200009\n",
      "-rw-r--r--   1 evivancovid supergroup     373506 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200009/part-00001-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n",
      "drwxr-xr-x   - evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200010\n",
      "-rw-r--r--   1 evivancovid supergroup     402643 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200010/part-00001-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n",
      "drwxr-xr-x   - evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200011\n",
      "-rw-r--r--   1 evivancovid supergroup     406739 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200011/part-00001-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n",
      "drwxr-xr-x   - evivancovid supergroup          0 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200012\n",
      "-rw-r--r--   1 evivancovid supergroup     387426 2022-05-19 18:29 /public/data/nyse_parts/trade_month=200012/part-00001-5cc4c68c-7c7f-4bdb-ba0c-9de2955dab3e.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "\n",
    "hdfs dfs -ls -R /public/data/nyse_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f087af1b-60a8-4924-be77-06194bf4b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+------+-------+-------+\n",
      "|ticker|trade_date|open_price|close_price|  high|    low| volume|\n",
      "+------+----------+----------+-----------+------+-------+-------+\n",
      "|     A|  20001002|     49.13|      51.38| 49.13|  50.56|2151800|\n",
      "|    AA|  20001002|     75.57|      76.68| 72.75|   73.5|3354900|\n",
      "|   ABB|  20001002|     19.45|      19.45| 19.45|  19.45|      0|\n",
      "|   ABC|  20001002|    11.875|    12.2975| 11.75|12.2975|3649400|\n",
      "|   ABM|  20001002|     13.47|      13.69| 13.41|  13.47|  30400|\n",
      "|   ABT|  20001002|     47.94|       48.0| 47.31|  47.94|2545700|\n",
      "|   ABX|  20001002|     15.12|      15.19| 14.87|  14.94| 766900|\n",
      "|   ACP|  20001002|      9.06|       9.12|  9.06|   9.12|   2500|\n",
      "|   ACV|  20001002|     19.29|      19.37| 18.96|  19.25|  75000|\n",
      "|   ADC|  20001002|     14.87|       15.0| 14.69|   15.0|   5000|\n",
      "|   ADM|  20001002|      8.39|       8.69|  8.21|   8.69|3271169|\n",
      "|   ADX|  20001002|     25.66|      25.75|  25.5|  25.53|  12000|\n",
      "|   AED|  20001002|      21.0|       21.0|  19.0|   19.0|    175|\n",
      "|   AEE|  20001002|     42.12|       42.5| 40.94|   42.5| 633100|\n",
      "|   AEG|  20001002|      36.6|      36.96| 36.54|  36.84| 177008|\n",
      "|   AEM|  20001002|      5.81|       5.94|  5.81|   5.81|  17400|\n",
      "|   AEO|  20001002|    10.462|     11.172|10.462| 10.859|2055600|\n",
      "|   AEP|  20001002|     39.12|      39.25| 38.06|  39.06| 935000|\n",
      "|   AES|  20001002|     68.69|      71.75| 67.56|  70.62|2526500|\n",
      "| AES-C|  20001002|    103.31|     106.44| 100.5|  105.0|  63100|\n",
      "+------+----------+----------+-----------+------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"/public/data/nyse_parts/trade_month=200010\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "940a7314-8a5c-4362-8928-b4bf7b063089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+------+-------+--------+-----------+\n",
      "|ticker|trade_date|open_price|close_price|  high|    low|  volume|trade_month|\n",
      "+------+----------+----------+-----------+------+-------+--------+-----------+\n",
      "|     A|  20000301|     104.5|     111.75|104.25| 109.13|  742400|     200003|\n",
      "|    AA|  20000301|    102.66|    106.215|99.195|104.625| 2390300|     200003|\n",
      "|   ABB|  20000301|      22.0|       22.0|  22.0|   22.0|     800|     200003|\n",
      "|   ABC|  20000301|     3.655|       3.78|  3.64| 3.7175|  342900|     200003|\n",
      "|   ABM|  20000301|      12.6|      12.72| 12.47|   12.6|  241000|     200003|\n",
      "|   ABT|  20000301|     33.13|       34.0| 32.75|  33.81| 3832400|     200003|\n",
      "|   ABX|  20000301|     16.62|      16.62| 16.37|  16.62|  864600|     200003|\n",
      "|   ACP|  20000301|      7.69|       7.69|  7.69|   7.69|    1700|     200003|\n",
      "|   ACV|  20000301|     14.33|      14.41| 13.91|  14.29|  103200|     200003|\n",
      "|   ADC|  20000301|     13.56|      13.87|  13.5|  13.87|    9500|     200003|\n",
      "|   ADM|  20000301|      9.01|       9.41|  9.01|   9.35| 2075785|     200003|\n",
      "|   ADX|  20000301|     21.97|      22.25| 21.87|  22.12|  123450|     200003|\n",
      "|   AED|  20000301|      18.0|       18.0|  16.0|   16.5|    3150|     200003|\n",
      "|   AEE|  20000301|     29.81|      29.94|  29.0|   29.5|  317700|     200003|\n",
      "|   AEG|  20000301|     33.38|      34.62| 32.99|  34.13|  280800|     200003|\n",
      "|   AEM|  20000301|       7.0|       7.06|  6.94|   6.94|  115900|     200003|\n",
      "|   AEO|  20000301|     9.378|     10.048| 8.338|  8.548|12864200|     200003|\n",
      "|   AEP|  20000301|     28.12|      28.19|  27.5|  27.56|  324200|     200003|\n",
      "|   AES|  20000301|     41.91|      42.19| 40.44|  40.97| 1697600|     200003|\n",
      "| AES-C|  20000301|     67.87|       69.5|  64.5|   65.5|   40600|     200003|\n",
      "+------+----------+----------+-----------+------+-------+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark. \\\n",
    "    read. \\\n",
    "    parquet(\"/public/data/nyse_parts\"). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41715bbb-f055-40da-b815-922fa791cad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>ticker</th><th>trade_date</th><th>open_price</th><th>close_price</th><th>high</th><th>low</th><th>volume</th><th>trade_month</th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----------+----------+-----------+----+---+------+-----------+\n",
       "|ticker|trade_date|open_price|close_price|high|low|volume|trade_month|\n",
       "+------+----------+----------+-----------+----+---+------+-----------+\n",
       "+------+----------+----------+-----------+----+---+------+-----------+"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark. \\\n",
    "    catalog. \\\n",
    "    createTable('nyseParts',\n",
    "                path=\"/public/data/nyse_parts\",\n",
    "                source='parquet'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd4edb4b-796f-49e4-9da3-3c59922663b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+----+---+------+-----------+\n",
      "|ticker|trade_date|open_price|close_price|high|low|volume|trade_month|\n",
      "+------+----------+----------+-----------+----+---+------+-----------+\n",
      "+------+----------+----------+-----------+----+---+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"nyseParts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdf9747f-42e8-4b6d-beb7-37a63c6db848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|partition|\n",
      "+---------+\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW PARTITIONS nyseParts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36b23516-aef5-4f9c-8d47-00ea316d8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.recoverPartitions(\"nyseParts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7734b719-7c2b-4843-a28c-e4b1a9ea4de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         partition|\n",
      "+------------------+\n",
      "|trade_month=200001|\n",
      "|trade_month=200002|\n",
      "|trade_month=200003|\n",
      "|trade_month=200004|\n",
      "|trade_month=200005|\n",
      "|trade_month=200006|\n",
      "|trade_month=200007|\n",
      "|trade_month=200008|\n",
      "|trade_month=200009|\n",
      "|trade_month=200010|\n",
      "|trade_month=200011|\n",
      "|trade_month=200012|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW PARTITIONS nyseParts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c909fefa-c3c0-4f96-a593-2498bc3afcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+------+-------+--------+-----------+\n",
      "|ticker|trade_date|open_price|close_price|  high|    low|  volume|trade_month|\n",
      "+------+----------+----------+-----------+------+-------+--------+-----------+\n",
      "|     A|  20000301|     104.5|     111.75|104.25| 109.13|  742400|     200003|\n",
      "|    AA|  20000301|    102.66|    106.215|99.195|104.625| 2390300|     200003|\n",
      "|   ABB|  20000301|      22.0|       22.0|  22.0|   22.0|     800|     200003|\n",
      "|   ABC|  20000301|     3.655|       3.78|  3.64| 3.7175|  342900|     200003|\n",
      "|   ABM|  20000301|      12.6|      12.72| 12.47|   12.6|  241000|     200003|\n",
      "|   ABT|  20000301|     33.13|       34.0| 32.75|  33.81| 3832400|     200003|\n",
      "|   ABX|  20000301|     16.62|      16.62| 16.37|  16.62|  864600|     200003|\n",
      "|   ACP|  20000301|      7.69|       7.69|  7.69|   7.69|    1700|     200003|\n",
      "|   ACV|  20000301|     14.33|      14.41| 13.91|  14.29|  103200|     200003|\n",
      "|   ADC|  20000301|     13.56|      13.87|  13.5|  13.87|    9500|     200003|\n",
      "|   ADM|  20000301|      9.01|       9.41|  9.01|   9.35| 2075785|     200003|\n",
      "|   ADX|  20000301|     21.97|      22.25| 21.87|  22.12|  123450|     200003|\n",
      "|   AED|  20000301|      18.0|       18.0|  16.0|   16.5|    3150|     200003|\n",
      "|   AEE|  20000301|     29.81|      29.94|  29.0|   29.5|  317700|     200003|\n",
      "|   AEG|  20000301|     33.38|      34.62| 32.99|  34.13|  280800|     200003|\n",
      "|   AEM|  20000301|       7.0|       7.06|  6.94|   6.94|  115900|     200003|\n",
      "|   AEO|  20000301|     9.378|     10.048| 8.338|  8.548|12864200|     200003|\n",
      "|   AEP|  20000301|     28.12|      28.19|  27.5|  27.56|  324200|     200003|\n",
      "|   AES|  20000301|     41.91|      42.19| 40.44|  40.97| 1697600|     200003|\n",
      "| AES-C|  20000301|     67.87|       69.5|  64.5|   65.5|   40600|     200003|\n",
      "+------+----------+----------+-----------+------+-------+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"nyseParts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61c52cd7-5d28-477b-938c-741bf9a81d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>trade_month</th><th>count(1)</th></tr>\n",
       "<tr><td>200001</td><td>25229</td></tr>\n",
       "<tr><td>200004</td><td>24265</td></tr>\n",
       "<tr><td>200009</td><td>25819</td></tr>\n",
       "<tr><td>200003</td><td>27759</td></tr>\n",
       "<tr><td>200010</td><td>27174</td></tr>\n",
       "<tr><td>200008</td><td>28213</td></tr>\n",
       "<tr><td>200006</td><td>26810</td></tr>\n",
       "<tr><td>200012</td><td>26005</td></tr>\n",
       "<tr><td>200007</td><td>25705</td></tr>\n",
       "<tr><td>200011</td><td>27228</td></tr>\n",
       "<tr><td>200005</td><td>27934</td></tr>\n",
       "<tr><td>200002</td><td>25286</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+--------+\n",
       "|trade_month|count(1)|\n",
       "+-----------+--------+\n",
       "|     200001|   25229|\n",
       "|     200004|   24265|\n",
       "|     200009|   25819|\n",
       "|     200003|   27759|\n",
       "|     200010|   27174|\n",
       "|     200008|   28213|\n",
       "|     200006|   26810|\n",
       "|     200012|   26005|\n",
       "|     200007|   25705|\n",
       "|     200011|   27228|\n",
       "|     200005|   27934|\n",
       "|     200002|   25286|\n",
       "+-----------+--------+"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT trade_month, count(1) FROM nyseParts GROUP BY trade_month\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae19862-ac52-4b3c-bee1-af0ae0753565",
   "metadata": {},
   "source": [
    "# Creating Temp Views\n",
    "\n",
    "We can create a temporary view for a DataDrame using **createTempView** or **createOrReplaceTempView**.\n",
    "\n",
    "**createOrReplaceTempView** will repalce the existing view, if it already exists.\n",
    "\n",
    "While tables in Metastore are permanent, views are temporary, once the application exits, temporary views will be deleted or flushed out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b71aeb6-ae13-45ea-b2a7-09b576bd4f07",
   "metadata": {},
   "source": [
    "# Using Spark SQL\n",
    "\n",
    "Once tables in Metastore or temp view are created, we can run queries against the tables or temporary views to perform all standard transformations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11892207-3555-4b32-8912-caf1231e98b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
