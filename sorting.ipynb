{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45198951-47f7-47d6-a03b-52f068bdde53",
   "metadata": {},
   "source": [
    "# Overview of Sorting Data\n",
    "\n",
    "We can use **orderBy** or **sort** to sort the date in a DataFrame.\n",
    "\n",
    "We can perform composite sorting by passing multiple columns or expressions. By default data is sorted in ascending order, however, we can change to descending by applying **desc()** functions on the column. \n",
    "\n",
    "If the sorted column contains *NULL* values those will come on top of the sort, however we can change the position of these values to the very last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5d9ec5-be73-4d72-8560-f8969627c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd22b75-431c-4891-af5b-f57bb64938c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'evivancovid | Python - Basic Transformations'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813eeaf2-e95d-4bb3-9e5d-b975fc681490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|    2|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees = [(1, \"Scott\", \"Tiger\", 1000.0, 10,\n",
    "                      \"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n",
    "                     ),\n",
    "                     (2, \"Henry\", \"Ford\", 1250.0, None,\n",
    "                      \"India\", \"+91 234 567 8901\", \"456 78 9123\"\n",
    "                     ),\n",
    "                     (3, \"Nick\", \"Junior\", 750.0, '',\n",
    "                      \"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n",
    "                     ),\n",
    "                     (4, \"Bill\", \"Gomes\", 1500.0, 2,\n",
    "                      \"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n",
    "                     )\n",
    "                ]\n",
    "\n",
    "employeesDF = spark. \\\n",
    "    createDataFrame(employees,\n",
    "                    schema=\"\"\"employee_id INT, first_name STRING, \n",
    "                    last_name STRING, salary FLOAT, bonus STRING, nationality STRING,\n",
    "                    phone_number STRING, ssn STRING\"\"\"\n",
    "                   )\n",
    "\n",
    "employeesDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "175de592-fcc3-49e6-9230-4767e8711a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, upper, when, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69cbddbc-0075-4c0c-b952-34992cb353f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mwhen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Evaluates a list of conditions and returns one of multiple possible result expressions.\n",
       "If :func:`pyspark.sql.Column.otherwise` is not invoked, None is returned for unmatched\n",
       "conditions.\n",
       "\n",
       ".. versionadded:: 1.4.0\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "condition : :class:`~pyspark.sql.Column`\n",
       "    a boolean :class:`~pyspark.sql.Column` expression.\n",
       "value :\n",
       "    a literal value, or a :class:`~pyspark.sql.Column` expression.\n",
       "\n",
       ">>> df.select(when(df['age'] == 2, 3).otherwise(4).alias(\"age\")).collect()\n",
       "[Row(age=3), Row(age=4)]\n",
       "\n",
       ">>> df.select(when(df.age == 2, df.age + 1).alias(\"age\")).collect()\n",
       "[Row(age=3), Row(age=None)]\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/spark3/python/pyspark/sql/functions.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "when?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a1e6cc-d778-45ab-9b8f-1abeb6ccad2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get employees data in ascending order by nationality. Data related to United States should come at top always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e66b2fa-40d6-4b6f-a2e7-a7e3a361e53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|sort_column|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|          0|\n",
      "|          4|      Bill|    Gomes|1500.0|    2|     AUSTRALIA|+61 987 654 3210|789 12 6118|          1|\n",
      "|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|          1|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|          1|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DataFrame Style\n",
    "\n",
    "employeesDF. \\\n",
    "    withColumn('sort_column', when(upper(col('nationality')) == 'UNITED STATES', 0).otherwise(1)). \\\n",
    "    orderBy('sort_column', 'nationality'). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5c290ea-8662-46bd-aa4f-4fc05bb1fba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|sort_column|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|          0|\n",
      "|          4|      Bill|    Gomes|1500.0|    2|     AUSTRALIA|+61 987 654 3210|789 12 6118|          1|\n",
      "|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|          1|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|          1|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQl Style\n",
    "\n",
    "employeesDF. \\\n",
    "    withColumn('sort_column', when(upper(col('nationality')) == 'UNITED STATES', 0).otherwise(1)). \\\n",
    "    orderBy('sort_column', 'nationality'). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a6567-1cb0-45fa-bb99-f90810a5e42e",
   "metadata": {},
   "source": [
    "### Sort the data in employeesDF using bonus. Data should be sorted numerically and null and empty values should come at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbf5f9dd-9157-4962-9565-0ac6a1af17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "c= col('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c8c63b1-dfc2-4a0b-8ef7-fd96072cc088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method _ in module pyspark.sql.column:\n",
      "\n",
      "_() method of pyspark.sql.column.Column instance\n",
      "    Returns a sort expression based on ascending order of the column, and null values\n",
      "    appear after non-null values.\n",
      "    \n",
      "    .. versionadded:: 2.4.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from pyspark.sql import Row\n",
      "    >>> df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], [\"name\", \"height\"])\n",
      "    >>> df.select(df.name).orderBy(df.name.asc_nulls_last()).collect()\n",
      "    [Row(name='Alice'), Row(name='Tom'), Row(name=None)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(c.asc_nulls_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d375fbf1-f67e-4551-9ff9-b8a30cab9dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          4|      Bill|    Gomes|1500.0|    2|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.orderBy(\n",
    "    employeesDF.bonus.cast('int').asc_nulls_last()).\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af91953-5a5e-498c-9ec9-dfa5fec2126b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
